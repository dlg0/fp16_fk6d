\section{Iterative Refinement Techniques}\label{sec:ir}
\cre{some text about iterative refinement that the factorization happen in low precision while the IR happen in FP16}

\section{Mixed-precision algorithms}\label{sec:mixedp}
\cre{
Here we will talk that basic FP16 LU will not work properly and for that we needed 
1- mixed precision factorization
2- tensor cores that does accumulation in FP32
}


\section{Algorithmic Advancements}\label{sec:mixedp}
\cre{
Here we can talk about classical versus GMRES based refinement and say that for FP16 classical may fail while GMRES will recover and I can add a graph about this}

